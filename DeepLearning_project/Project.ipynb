{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 521153S, Deep Learning Final Project: Mini Image classification Competition with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline \n",
    "### In this assignment, you will learn:\n",
    "* Combine all you learned from the previous assignments.\n",
    "* Build your own CNN as you like with Pytorch, train and validate it on a given dataset.\n",
    "* Test your CNN model on our server.\n",
    "\n",
    "### Tasks (<span style=\"color:orange\">40 points</span>)\n",
    "We want to keep the task as clean and simple as possible. \n",
    "1. You would be given a dataset containing 45,000 grayscale 32x32 images. Also, we will set a private testing data and upload it to our server. You could only use the private testing data to test your model. Instructions about evaluating your model would be given along with the project in Moodle.\n",
    "2. Before evaluating your model on the server, you have to train your model based on the given 45,000 images. Specifically, in these images, there are nine classes, and each class has 5000 images. The testing data on the server has 9000 images, and each class has 1000 images.\n",
    "3. To get a good CNN model, basically, there are some rules for you to follow which would be considered when grading your report:\n",
    "  * Make the best out of the given images. It means you have to split it into training and validation set, training your model on the training set and validating the trained model on the validation set. If the accuracy on the validation set is not good, then you have to adjust your CNN model structure or some adjustable parameters. For example, batch size, learning rate, momentum on SGD, lambda in weight decay, etc.  Then retrain your model until the accuracy on the validation set is good enough because the testing data would have similar accuracy with the validation set. \n",
    "  * It also means that you could do some augmentation on the training set. This includes randomly flipping, cropping a small window in a random location within the image(refer to assignment 4), adding some noise, resizing-and-cropping, etc. All these are to make the training process more tolerant. \n",
    "  * From the CNN structure perspective, you also need to design your CNN model by yourself. Well-known network architecture you can use includes [ResNet](https://arxiv.org/abs/1512.03385), [Inception](https://arxiv.org/abs/1512.00567), [VGGNet](https://arxiv.org/abs/1409.1556), [DenseNet](https://arxiv.org/abs/1608.06993), [MobileNet](https://arxiv.org/abs/1801.04381), [ShuffleNet](https://arxiv.org/abs/1807.11164), [ResNeXt](https://arxiv.org/abs/1611.05431) etc. \n",
    "4. Similar to real-life applications, your model will be tested with unknown data. In this project,  after training and validating the model, you need to test it on our hold-on testing dataset. We will provide you with a submission server and a leaderboard. The instructions would be given alongside the project in Moodle. \n",
    "5. Please give a pdf report (also your source code, e.g., this Jupyter notebook file), documenting the whole model training process and also the evaluated accuracy on the server. Tensorboard visualization is also necessary for your report to visualize your network structure, accuracy, and losses, etc. as done in assignment 4.\n",
    "6. You need to return the pdf report as well as your trained model (a checkpoint file) with your source code file to moodle. We will run your model on the server and compare the results with the one written in the reports. \n",
    "\n",
    "### Grading\n",
    "You can get 40 points in total.\n",
    "  * You will get <span style=\"color:orange;font-weight:bold\">20 points</span> if your model achieve more than 82.5% of the testing accuracy.\n",
    "  * You will get <span style=\"color:orange;font-weight:bold\">20 points</span> if your report is clear and well-organized.\n",
    "  \n",
    "### Files you have to submit\n",
    "please submit a .zip file containing:\n",
    "1. a pdf report;\n",
    "2. source code files (jupyter notebook or common python files);\n",
    "3. a checkpoint file (which saves your trained model).\n",
    "\n",
    "### Group members\n",
    "Maximum 2 members. \n",
    "\n",
    "\n",
    "### Environment\n",
    "Python 3, Numpy, matplotlib, torch, torchvision...\n",
    "\n",
    "### Dataset\n",
    "Please follow the code below to download the 45,000 images and corresponding labels. <br>\n",
    "We have already split them into training and validation set; please refer to assignment 3 and 4 to create your DataLoader, with your data augmentation methods. Good luck. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os, time\n",
    "import torch \n",
    "import requests, zipfile, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import download_given_data, get_preds_figure\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils\n",
    "import random, matplotlib\n",
    "import pandas as pd\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "download_given_data('./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
